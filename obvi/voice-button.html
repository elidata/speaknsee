<!-- // Copyright 2017 Google Inc.
//
//     Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
//     You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
//     Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
//     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//     See the License for the specific language governing permissions and
// limitations under the License. -->

<link rel="import" href="../polymer/polymer-element.html">
<link rel="import" href="../paper-behaviors/paper-ripple-behavior.html">
<link href="https://fonts.googleapis.com/css?family=Noto+Sans" rel="stylesheet">

<script src="voice-recorder.js"></script>
<script src="voice-viz.js"></script>
<script src="voice-translations.js"></script>

<dom-module id="voice-button">

  <!-- 
  Note: deprecation warning for styling master document doesn't apply within <template> tags
  Read more: https://www.polymer-project.org/blog/2017-10-18-upcoming-changes
   -->

  <template>

    <style>

      /* shadow DOM styles */      
      
      :host {
        /* red active color */
        --active-color: #fe4042;
        /* background color for button */
        --button-color: #FFFFFF;
        /* circle viz color (opacity is at 0.2) */
        --circle-viz-color:#000000;
        /* diameter of button, option can be changed by user */
        --button-diameter:100px;
        /* mic color*/
        --mic-color:#FFFFFF;
        /* text color, used for warning messaging*/
        --text-color:#666;
        
        display: inline-block;
        height: var(--button-diameter);
        width: var(--button-diameter);
      }

      #paper-button{
        outline:none;
        background:var(--button-color);
        border:none;
        width:100%;
        height:100%;
        min-width:0;
        border-radius:50%;
        cursor:pointer;
        transition: all ease 0.25s;
        background-size: 100%;
        background-repeat: no-repeat;
        background-position: center;
        box-shadow: 0 2px 5px 0 rgba(0,0,0,.26);
        z-index:2;
        position:absolute;
        opacity:0.8;
        margin:0;
        left:0;
      }

      #paper-button.flat{
        box-shadow:0px 0px 0px 0px;
      }

      #paper-button:hover{
        box-shadow: 0 4px 7px 0 rgba(0,0,0,.20);
      }

      #paper-button.disabled{
        box-shadow: 0px 0px 0px 0px;
        cursor:not-allowed;
        opacity:0.5;
      }

      #paper-button.listening, #paper-button.user-input{
        box-shadow: 0px 0px 0px 0px;
        opacity:1; 
        background:var(--active-color);
      }

      #paper-button.flat:hover{
        box-shadow:0px 0px 0px 0px; 
      }

      #paper-button.disabled:hover{
        box-shadow: 0px 0px 0px 0px;
      }

      #circle-viz-container{
        position:absolute;
        z-index:0;
        opacity:0;
      }

      .svg-container{
        position:absolute;
        top:0;
        left:0;
        width:100%;
        height:100%;
        background:rgba(255, 0, 0, 0);
        z-index:3;
        pointer-events: none;
      }

      #mic-svg, #mic-svg-disabled, #mic-loading{
        height: 64%;
        width:100%;
        display: block;
        position: absolute;
        top: -11%;
        left: 0px;
        transform:translate(0, 50%);
        z-index:3;
        pointer-events:none;
      }

      #mic-loading {
        opacity: 0;
        top: -14%;
        transform: translate(0, 50%) scale(0.8, 0.8);
      }

      #mic-loading circle:nth-child(1) {
        animation: 0.7s micLoading 0s infinite;
      }

      #mic-loading circle:nth-child(2) {
        animation: 0.7s micLoading 0.3s infinite;
      }

      #mic-loading circle:nth-child(3) {
        animation: 0.7s micLoading 0.5s infinite;
      }

      @keyframes micLoading {
        to {
          fill-opacity: 0;
        }
        from {
          fill-opacity: 1;
        }
      }


      /* show the disabled mic when in disabled state */
      .container #mic-svg-disabled{ display:none; }
      .container.disabled #mic-svg-disabled{ display:block; }
      .container.disabled #mic-svg{ display:none; }
      .container.listening #mic-svg, .container.user-input #mic-svg { fill: #FFFFFF !important; }


      .container{
        position:absolute;
        height: var(--button-diameter);
        width: var(--button-diameter);
      }

      .circle{
        width:calc(var(--button-diameter) - 4px);
        height:calc(var(--button-diameter) - 4px);
        background-color:var(--circle-viz-color);
        opacity:0.2;
        border-radius:50%;
        position:absolute;
        transform-origin: center center;
        transform:scale(1);
      }

      #mic-not-allowed{
        font-family: 'Noto Sans', sans-serif;
        font-size: 1.0em;
        -webkit-font-smoothing: antialiased;
        color: var(--text-color);
        width: 210px;
        top: 100%;
        display: none;
        position: absolute;
        margin-left: 0px;
        transform: translateX(-50%);
        left: 50%;
        font-weight: 400;
        text-align: center;
        vertical-align: bottom;
        margin-top: 15px;
      }
      #mic-not-allowed.show{
        display:block;
      }

      paper-ripple{
        position:absolute;
      }

    </style>


    <!-- shadow DOM -->
    <div class$="container [[state]]">

      <!-- rings that scale out from button with user input (only available with autodetect)  -->
      <div id="circle-viz-container"></div>
      
      <!-- clickable button -->
      <button id="paper-button" class$="voice-button [[state]] [[flatStr]] [[autoDetectStr]]"><paper-ripple></paper-ripple></button>
      
      <div class="svg-container">
        <!-- mic icon -->
        <svg id="mic-svg" xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="#000000">
            <path d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.48 6-3.3 6-6.72h-1.7z"/>
            <path d="M0 0h24v24H0z" fill="none"/>
        </svg>
        <svg id="mic-svg-disabled" xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="#000000">
            <path d="M0 0h24v24H0zm0 0h24v24H0z" fill="none"/>
            <path d="M19 11h-1.7c0 .74-.16 1.43-.43 2.05l1.23 1.23c.56-.98.9-2.09.9-3.28zm-4.02.17c0-.06.02-.11.02-.17V5c0-1.66-1.34-3-3-3S9 3.34 9 5v.18l5.98 5.99zM4.27 3L3 4.27l6.01 6.01V11c0 1.66 1.33 3 2.99 3 .22 0 .44-.03.65-.08l1.66 1.66c-.71.33-1.5.52-2.31.52-2.76 0-5.3-2.1-5.3-5.1H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c.91-.13 1.77-.45 2.54-.9L19.73 21 21 19.73 4.27 3z"/>
        </svg>
      <svg id="mic-loading" version="1.1" xmlns="http://www.w3.org/2000/svg" x="0px" y="0px"
      viewBox="0 0 727 353" fill="#ffffff">
        <circle cx="136.5" cy="176.5" r="73.5"/>
        <circle cx="363.5" cy="176.5" r="73.5"/>
        <circle cx="590.5" cy="176.5" r="73.5"/>
      </svg>
      </div>

      <div id="mic-not-allowed">Cannot access microphone</div>
    
    </div>

  </template>

  <script>
    
    const ListeningState = Object.freeze({
      IDLE: 'idle',
      LISTENING: 'listening',
      USER_INPUT: 'user-input',
      DISABLED: 'disabled'
    });

    const KeyboardTriggers = Object.freeze({
      ALL_KEYS: 'all-keys',
      SPACE_BAR: 'space-bar',
      NONE: 'none'
    })

    // maintain one audio stream, immediately, to work in safari
    // see here: https://forums.developer.apple.com/thread/86286
    var audioStream;

    class VoiceButton extends Polymer.Element {
      
      static get is() {
        return 'voice-button';
      }

      static get properties(){
        return {
          
          flat: {
            type: Boolean,
            reflectToAttribute: true,
            value: false
          },
          autodetect: {
            type: Boolean,
            notify: false,
            reflectToAttribute: true,
            value: false
          },
          clickForPermission: {
            type: Boolean,
            notify: false,
            reflectToAttribute: true,
            value: false
          },
          hidePermissionText: {
            type: Boolean,
            notify: false,
            reflectToAttribute: true,
            value: false
          },
          language: {
            type: String,
            reflectToAttribute: true,
            value: 'en-US'
          },
          disabled: {
            type: Boolean,
            notify: true,
            reflectToAttribute: true,
            value: false,
            observer: '_onEnabledStateChange'
          },
          keyboardTrigger: {
            type: String,
            reflectToAttribute: true,
            value: KeyboardTriggers.SPACE_BAR
          },
          pressed: {
            type: Boolean,
            notify: false,
            reflectToAttribute: true,
            readOnly: true,
            value: false
          },
          cloudSpeechApiKey: {
            type:String,
            readOnly: false,
            reflectToAttribute: false,
            value: null
          },
          state: {
            type: String,
            notify: false,
            readOnly: true,
            reflectToAttribute: true,
            value: ListeningState.IDLE,
            observer: '_onStateChange'
          },
          supported: {
            type: Boolean,
            readOnly: true,
            reflectToAttribute: true,
            value: true
          },
          flatStr: String,
          autoDetectStr: String
        }
      }

      constructor() {
        super();
        this._setState(ListeningState.IDLE)
      }

      ready() {
        super.ready();

        this.useCloudSpeech = false;

        // warn host if a cloud speech api isn't provided
        if(typeof this.cloudSpeechApiKey !== 'string'){
          console.warn('For fallback support, it is recommended to provide a cloud-speech-api-key.')
        }
        
        // Get the SpeechRecognition object
        // only allow prefixed webkitSpeechRecognition for Chrome, Opera has support but doesn't work
        // As test: https://www.google.com/intl/en/chrome/demos/speech.html
        // Support table: https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition#Browser_compatibility
        // Opera 8.0+
        var isOpera = (!!window.opr && !!opr.addons) || !!window.opera || navigator.userAgent.indexOf(' OPR/') >= 0;
        const SpeechRecognition = window['webkitSpeechRecognition'];
        if(typeof SpeechRecognition === 'undefined' || isOpera){      
          // make sure you have a Cloud Speech API key 
          if(typeof this.cloudSpeechApiKey !== 'string'){
            console.error('Need to provide a cloud-speech-api-key.')
            this._setState(ListeningState.DISABLED)
            this.set('disabled', true)
            return;
          }
          // check for WebRTC support
          // notice at the release of iOS11, webRTC has not reached WebKit
          // more info: https://stackoverflow.com/questions/45055329/does-webkit-in-ios-11-beta-support-webrtc
          if (this.checkWebRTC()) {
            this.useCloudSpeech = true;
          } else {
            this._setSupported(false)
            // disable button if speech recognition isn't available
            this._setState(ListeningState.DISABLED)
            this.set('disabled', true)
            console.error('WebRTC is not supported on this browser.');
            return;
          }
        }

        this.set('flatStr', (this.flat) ? 'flat' : '')
        this.set('autoDetectStr', (this.autodetect) ? 'auto-detect' : '')

        var micColor = getComputedStyle(this).getPropertyValue('--mic-color');

        this.googleMicEl = this.$['mic-svg'];
        this.googleMicLoaderEl = this.$['mic-loading'];
        this.googleMicDisabledEl = this.$['mic-svg-disabled'];
        this.buttonEl = this.$['paper-button'];

        let circleVizContainer = this.$['circle-viz-container'];
        this.circleViz = new CircleViz(circleVizContainer, () => {
          this.onSpeechError({error: 'not-allowed'});
        });
        // if user wants to ask for permission when clicked, then wait
        if(!this.clickForPermission){
          this.circleViz.attachUserMediaStream();
        }

        // set mic color
        this.googleMicEl.style.fill = this.googleMicDisabledEl.style.fill = micColor;

        // mouse listeners
        this.buttonEl.addEventListener('mousedown', this.mouseDown.bind(this));
        this.buttonEl.addEventListener('mouseup', this.mouseUp.bind(this));

        // listen for space bar on document
        if(this.keyboardTrigger !== KeyboardTriggers.NONE){
          document.body.addEventListener('keydown', this.keyDown.bind(this));
          document.body.addEventListener('keyup', this.keyUp.bind(this)) ;
        }

        if(this.hidePermissionText){
          this.$['mic-not-allowed'].style.display = 'none';
        }

        // setup microphone-not-allowed messaging
        var translatedCopy = this.getTranslation();
        if(translatedCopy){
          this.$['mic-not-allowed'].innerHTML = translatedCopy;
        }

        if (!this.useCloudSpeech) {
          // set up speech recognition
          this.recognition = new SpeechRecognition();
          if(this.language != '') this.recognition.lang = this.language;
          // weird issue where `interimResults = true` is cutting off speech 
          // see comment here: https://developers.google.com/web/updates/2013/01/Voice-Driven-Web-Apps-Introduction-to-the-Web-Speech-API?google_comment_id=z13msdqh0yqpyrpfx23gw5xa2wu0ypzwj04
          const isMobile = window.mobileAndTabletcheck();
          this.recognition.interimResults = !isMobile;
          this.recognition.continuous =  (isMobile) ? false : !this.autodetect;
          this.recognition.maxAlternatives = 0;


          // add event listeners
          this.recognition.onresult = this.onSpeechResult.bind(this);
          this.recognition.onspeechend = this.onSpeechEnd.bind(this);
          this.recognition.onerror = this.onSpeechError.bind(this);
        } else {
          // get blob data to send up to Cloud Speech API
          this.voiceRecorder = new VoiceRecorder(this.autodetect, this.onStopRecordingVoiceComplete.bind(this));
        }
      }

      getTranslation(){
        var full = window.componentTranslations.micNotAllowed[this.language];
        if(typeof full !== 'undefined') return full;
        var half = window.componentTranslations.micNotAllowed[this.language.split('-')[0].toLowerCase()];
        if(typeof half !== 'undefined') return half;
        return null;
      }
    
      keyDown(event){
        if(this.state === ListeningState.DISABLED) return;
        this.pressed = true;
        if((event.keyCode == 32 && this.keyboardTrigger === KeyboardTriggers.SPACE_BAR) || 
          (this.keyboardTrigger === KeyboardTriggers.ALL_KEYS)){
          if(this.state !== ListeningState.USER_INPUT && this.state !== ListeningState.LISTENING){
            this.startListening();
          }
        }
      }

      keyUp(event){
        if(this.state === ListeningState.DISABLED) return;
        this.pressed = false;
        if((event.keyCode == 32 && this.keyboardTrigger === KeyboardTriggers.SPACE_BAR) || 
          (this.keyboardTrigger === KeyboardTriggers.ALL_KEYS)){

          if(this.autodetect && (this.state === ListeningState.IDLE || this.state === ListeningState.USER_INPUT)){
            this.stopListening();
          }
          else if(!this.autodetect){
            this.stopListening();
          }
        }
      }

      mouseDown(event){
        // If we use Cloud Speech, we'll have it start and stop by a toggle
        if(this.state === ListeningState.DISABLED) return;
        this.pressed = true;
        if(this.state !== ListeningState.USER_INPUT && this.state !== ListeningState.LISTENING){
          this.startListening();
        }else if(this.state === ListeningState.LISTENING) {
          this.stopListening();
        }
      }

      mouseUp(event){
        if(this.state === ListeningState.DISABLED) return;

        // if in autodetect mode but user taps again to stop
        if(this.autodetect && (this.state === ListeningState.IDLE || this.state === ListeningState.USER_INPUT)){
          this.stopListening();
        }
        else if(!this.autodetect){  // press & hold mode, stop listening when mouse is up
          this.stopListening();
        }

        this.buttonEl.blur();
        this.pressed = false;
      }

      startRecordingVoice() {
        this.isRecording = true;
        this.voiceRecorder.startRecord();
      }

      // need audio blob in Base64 to send to CloudSpeech API
      blobToBase64(blob, cb){
        let reader = new FileReader();
        reader.onloadend = () => {
          let dataUrl = reader.result;
          let base64 = dataUrl.split(',')[1];
          cb(base64);
        }
        reader.onerror = (err) => {
          console.error('Error in reading blob', err)
        }
        reader.readAsDataURL(blob);
      }


      onStopRecordingVoiceComplete(blob){
        if(this.isRecording){
          this.isRecording = false;
          this._setState(ListeningState.IDLE);
          this.circleViz.stopAnimation();
          this.postTranscription(blob);
        }
      }

      postTranscription(blob){
        this.showLoader();

        this.blobToBase64(blob, (data) => {
          let postBody = `{
              "config": {
                "encoding": "LINEAR16",
                "languageCode": "en-US",
                "enableWordTimeOffsets": false
              },
              "audio": {
                "content": "${data}"
              }
            }`;
          let xhr = new XMLHttpRequest();
          xhr.open("POST", 'https://speech.googleapis.com/v1/speech:recognize?key=' + this.cloudSpeechApiKey, true);
          xhr.onload = (data) => {
            // Request finished. Do processing here.
            // hide the dot loader
            this.hideLoader();

            let response = JSON.parse(xhr.responseText);
            if (
              response &&
              response.results &&
              response.results[0] &&
              response.results[0].alternatives &&
              response.results[0].alternatives[0] &&
              response.results[0].alternatives[0].transcript
            ) {
              let text = response.results[0].alternatives[0].transcript || '';
              let event = {
                speechResult : text,
                confidence : response.results[0].alternatives[0].confidence,
                isFinal : true
              };
              this.dispatchEvent(new CustomEvent('onSpeech', {detail: event}));
            }
          }
          xhr.onerror = () => {
            console.error('Error occurred during Cloud Speech AJAX request.')
          }
          xhr.send(postBody);
        });
      }

      startListening(){
        if(this.clickForPermission){
          this.circleViz.attachUserMediaStream();
        }
        this._setState(ListeningState.LISTENING);
        if(!this.useCloudSpeech) {
          // start recognition
          this.recognition.start();
        } else {
          this.startRecordingVoice();
        }
        this.circleViz.startAnimation();
      }
      
      stopListening(){
        if(!this.useCloudSpeech) {
          this._setState(ListeningState.IDLE);
          this.circleViz.stopAnimation();
          this.recognition.stop();
          this.removeSpeechEventListeners();          
        } else {
          this.voiceRecorder.stopRecord();
        }
      }

      onSpeechResult(event){
        var result = {
          speechResult : event.results[0][0].transcript,
          confidence : event.results[0][0].confidence,
          isFinal : event.results[0].isFinal,
          sourceEvent: event
        }
        this._setState(ListeningState.USER_INPUT);
        this.dispatchEvent(new CustomEvent('onSpeech', {detail: result}));

        if(result.isFinal){
          this._setState(ListeningState.IDLE);
          this.circleViz.stopAnimation();
          if(this.autodetect){
            this.stopListening();
          }
        }
      }

      onSpeechEnd(){
        this._setState(ListeningState.IDLE);
        this.circleViz.stopAnimation();
        this.removeSpeechEventListeners();
      }

      onSpeechError(event){
        this._setState(ListeningState.IDLE);
        this.circleViz.stopAnimation();
        this.removeSpeechEventListeners();
        this.dispatchEvent(new CustomEvent('onSpeechError', {detail: event}));
        if(event.error === 'not-allowed'){
          this.$['mic-not-allowed'].classList.add('show');
          this._setState(ListeningState.DISABLED)
          this.set('disabled', true)
        }
      }


      removeSpeechEventListeners(){
        if(this.recognition){
          this.recognition.removeEventListener('result', this.onSpeechResult);
          this.recognition.removeEventListener('end', this.onSpeechEnd);
          this.recognition.removeEventListener('error', this.onSpeechError);
        }
      }

      _onEnabledStateChange(newValue, oldValue){
        if(this.disabled) this._setState(ListeningState.DISABLED);
        else this._setState(ListeningState.IDLE);
      }

      _onStateChange(newValue, oldValue){
        this.dispatchEvent(new CustomEvent('onStateChange', {detail: {newValue: newValue, oldValue: oldValue}}));
      }

      showLoader() {
        this.googleMicLoaderEl.style.opacity = 1;
        this.googleMicEl.style.display = 'none';
      }

      hideLoader() {
        this.googleMicLoaderEl.style.opacity = 0;
        this.googleMicEl.style.display = 'block';
      }

      checkWebRTC() {
        let audioCtx = (window.AudioContext || window.webkitAudioContext)
        if (
          (audioCtx) &&
          ((navigator.mediaDevices && navigator.mediaDevices.getUserMedia) || navigator.getUserMedia) &&
          (Worker)
        ) {
          return true;
        }
        console.error('Need to provide a cloud-speech-api-key for support on this browser.')
        return false;
      }

    }



    window.mobileAndTabletcheck = function() {
    var check = false;
    (function(a){if(/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino|android|ipad|playbook|silk/i.test(a)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0,4))) check = true;})(navigator.userAgent||navigator.vendor||window.opera);
    return check;
    };

    customElements.define(VoiceButton.is, VoiceButton);
  </script>

</dom-module>

